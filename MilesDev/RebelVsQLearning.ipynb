{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebel Vs QLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DETERMINISTICAGENTS import AggressiveAgent, RandomAgent, DeterminedAgent, FoldAgent\n",
    "from QLEARNINGAGENT import QLearningAgent\n",
    "from REBELAGENT import REBELAgent\n",
    "from CREATEENVIORMENT import createEnviorment\n",
    "from LEARNINGLOOP import learningLoop\n",
    "from PLOTTING import plot_cumulative_winnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_players = 6\n",
    "agents = [QLearningAgent(), REBELAgent(num_players=6), QLearningAgent(), QLearningAgent(), QLearningAgent(), QLearningAgent()]\n",
    "player_names = {0: 'QLearning1', 1: 'Rebel', 2: 'QLearning2', 3:'QLearning3',4:'QLearning4',5:'QLearning5'} # Rest are defaulted to player3, player4...\n",
    "# Should we only log the 0th players (here TrackedAgent1) private cards to hand history files\n",
    "track_single_player = False\n",
    "# Bounds for randomizing player stack sizes in reset()\n",
    "low_stack_bbs = 499\n",
    "high_stack_bbs = 500\n",
    "hand_history_location = 'MilesHands/'\n",
    "invalid_action_penalty = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1\n",
    "n_iterations = 1000\n",
    "total_winnings = []\n",
    "for t in range(n_trials):\n",
    "    table = createEnviorment(active_players, agents, player_names, low_stack_bbs, high_stack_bbs, hand_history_location, invalid_action_penalty, track_single_player)\n",
    "    table.seed(t)\n",
    "    player_winnings = learningLoop(table, agents, active_players, n_iterations)\n",
    "    print(f\"Trial {t+1} completed\")\n",
    "    total_winnings.append(player_winnings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RVQVDETRM = plot_cumulative_winnings(total_winnings, [\"Q Agent 1\", \"Rebel Agent\", \"Q Agent 2\", \"Q Agent 3\", \"Q Agent 4\", \"Q Agent 5\"], n_iterations)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
